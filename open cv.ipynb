{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ccff741",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfcf56ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "prototxtPath=os.path.sep.join([r'E:\\python\\mask\\face','deploy.prototxt'])\n",
    "weightsPath=os.path.sep.join([r'E:\\python\\mask\\face','res10_300x300_ssd_iter_140000.caffemodel'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "45a4a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=cv2.dnn.readNet(protopath,weightpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cadf28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(r'E:\\python\\mask\\mask_detector.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0c95389",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread(r'E:\\python\\mask\\mask.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07309b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[200, 177, 162],\n",
       "        [201, 178, 163],\n",
       "        [201, 178, 163],\n",
       "        ...,\n",
       "        [218, 200, 189],\n",
       "        [218, 200, 189],\n",
       "        [218, 200, 189]],\n",
       "\n",
       "       [[201, 178, 163],\n",
       "        [201, 178, 163],\n",
       "        [202, 179, 164],\n",
       "        ...,\n",
       "        [218, 200, 189],\n",
       "        [218, 200, 189],\n",
       "        [218, 200, 189]],\n",
       "\n",
       "       [[201, 178, 163],\n",
       "        [201, 178, 163],\n",
       "        [202, 179, 164],\n",
       "        ...,\n",
       "        [218, 200, 189],\n",
       "        [218, 200, 189],\n",
       "        [218, 200, 189]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[111, 111, 111],\n",
       "        [254, 254, 254],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[111, 111, 111],\n",
       "        [254, 254, 254],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[111, 111, 111],\n",
       "        [254, 254, 254],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "402452d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=img_to_array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90720f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(190, 265, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d96e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob=cv2.dnn.blobFromImage(image,1.0,(300,300),(104.0,177.0,213.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23a65da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  96.        ,   96.825     ,   97.        , ...,\n",
       "           114.        ,  114.        ,  114.        ],\n",
       "         [  96.45      ,   96.90375   ,   97.31874   , ...,\n",
       "           114.        ,  114.        ,  114.        ],\n",
       "         [  97.        ,   97.        ,   97.70833   , ...,\n",
       "           114.        ,  114.        ,  114.        ],\n",
       "         ...,\n",
       "         [   7.        ,  124.97499   ,  150.70833   , ...,\n",
       "           151.        ,  151.        ,  151.        ],\n",
       "         [   7.        ,  124.97499   ,  150.70833   , ...,\n",
       "           151.        ,  151.        ,  151.        ],\n",
       "         [   7.        ,  124.97499   ,  150.70833   , ...,\n",
       "           151.        ,  151.        ,  151.        ]],\n",
       "\n",
       "        [[   0.        ,    0.82499695,    1.        , ...,\n",
       "            23.        ,   23.        ,   23.        ],\n",
       "         [   0.44999695,    0.90374756,    1.3187408 , ...,\n",
       "            23.        ,   23.        ,   23.        ],\n",
       "         [   1.        ,    1.        ,    1.7083282 , ...,\n",
       "            23.        ,   23.        ,   23.        ],\n",
       "         ...,\n",
       "         [ -66.        ,   51.97499   ,   77.70833   , ...,\n",
       "            78.        ,   78.        ,   78.        ],\n",
       "         [ -66.        ,   51.97499   ,   77.70833   , ...,\n",
       "            78.        ,   78.        ,   78.        ],\n",
       "         [ -66.        ,   51.97499   ,   77.70833   , ...,\n",
       "            78.        ,   78.        ,   78.        ]],\n",
       "\n",
       "        [[ -51.        ,  -50.175003  ,  -50.        , ...,\n",
       "           -24.        ,  -24.        ,  -24.        ],\n",
       "         [ -50.550003  ,  -50.096252  ,  -49.68126   , ...,\n",
       "           -24.        ,  -24.        ,  -24.        ],\n",
       "         [ -50.        ,  -50.        ,  -49.29167   , ...,\n",
       "           -24.        ,  -24.        ,  -24.        ],\n",
       "         ...,\n",
       "         [-102.        ,   15.974991  ,   41.70833   , ...,\n",
       "            42.        ,   42.        ,   42.        ],\n",
       "         [-102.        ,   15.974991  ,   41.70833   , ...,\n",
       "            42.        ,   42.        ,   42.        ],\n",
       "         [-102.        ,   15.974991  ,   41.70833   , ...,\n",
       "            42.        ,   42.        ,   42.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1d40004",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.setInput(blob)\n",
    "detections=net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4bdd8e39",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-ae13ff150840>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m#we need the X,Y coordinates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mbox\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdetections\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0mstartX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstartY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mendX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mendY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'w' is not defined"
     ]
    }
   ],
   "source": [
    "#loop over the detections\n",
    "for i in range(0,detections.shape[2]):\n",
    "    confidence=detections[0,0,i,2]\n",
    "    \n",
    "    \n",
    "    if confidence>0.5:\n",
    "        #we need the X,Y coordinates\n",
    "        box=detections[0,0,i,3:7]*np.array([w,h,w,h])\n",
    "        (startX,startY,endX,endY)=box.astype('int')\n",
    "        \n",
    "        #ensure the bounding boxes fall within the dimensions of the frame\n",
    "        (startX,startY)=(max(0,startX),max(0,startY))\n",
    "        (endX,endY)=(min(w-1,endX), min(h-1,endY))\n",
    "        \n",
    "        \n",
    "        #extract the face ROI, convert it from BGR to RGB channel, resize it to 224,224 and preprocess it\n",
    "        face=image[startY:endY, startX:endX]\n",
    "        face=cv2.cvtColor(face,cv2.COLOR_BGR2RGB)\n",
    "        face=cv2.resize(face,(224,224))\n",
    "        face=img_to_array(face)\n",
    "        face=preprocess_input(face)\n",
    "        face=np.expand_dims(face,axis=0)\n",
    "        \n",
    "        (mask,withoutMask)=model.predict(face)[0]\n",
    "        \n",
    "        #determine the class label and color we will use to draw the bounding box and text\n",
    "        label='Mask' if mask>withoutMask else 'No Mask'\n",
    "        color=(0,255,0) if label=='Mask' else (0,0,255)\n",
    "        \n",
    "        #include the probability in the label\n",
    "        label=\"{}: {:.2f}%\".format(label,max(mask,withoutMask)*100)\n",
    "        \n",
    "        #display the label and bounding boxes\n",
    "        cv2.putText(image,label,(startX,startY-10),cv2.FONT_HERSHEY_SIMPLEX,0.45,color,2)\n",
    "        cv2.rectangle(image,(startX,startY),(endX,endY),color,2)\n",
    "        \n",
    "        \n",
    "        \n",
    "cv2.imshow(\"OutPut\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc5f509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
